{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_with_cpt-2.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv3aEfj1pY1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/openai/gpt-2.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbOnh3n7pmHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('gpt-2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhn-kI_qp9Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.12.0\n",
        "!pip3 install tensorflow==1.14.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUoudGpOp-Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3se06M5uibH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 download_model.py 345M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwnUtGZguvK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ_5rxMMyDlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('src')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLkxZBRKyGRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import model, sample, encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXEdUqJizfTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interact_model(raw_text,\n",
        "    model_name,\n",
        "    seed,\n",
        "    nsamples,\n",
        "    batch_size,\n",
        "    length,\n",
        "    temperature,\n",
        "    top_k,\n",
        "    models_dir\n",
        "):\n",
        "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "    assert nsamples % batch_size == 0\n",
        "\n",
        "    enc = encoder.get_encoder(model_name, models_dir)\n",
        "    hparams = model.default_hparams()\n",
        "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "        hparams.override_from_dict(json.load(f))\n",
        "\n",
        "    if length is None:\n",
        "        length = hparams.n_ctx // 2\n",
        "    elif length > hparams.n_ctx:\n",
        "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "        np.random.seed(seed)\n",
        "        tf.set_random_seed(seed)\n",
        "        output = sample.sample_sequence(\n",
        "            hparams=hparams, length=length,\n",
        "            context=context,\n",
        "            batch_size=batch_size,\n",
        "            temperature=temperature, top_k=top_k\n",
        "        )\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "        saver.restore(sess, ckpt)\n",
        "\n",
        "        while True:\n",
        "            context_tokens = enc.encode(raw_text)\n",
        "            generated = 0\n",
        "            for _ in range(nsamples // batch_size):\n",
        "                out = sess.run(output, feed_dict={\n",
        "                    context: [context_tokens for _ in range(batch_size)]\n",
        "                })[:, len(context_tokens):]\n",
        "                for i in range(batch_size):\n",
        "                    generated += 1\n",
        "                    text = enc.decode(out[i])\n",
        "                    #print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "                return text    \n",
        "                    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci4SK40tz7Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=interact_model(\"I went to a lounge to celebrate my birthday and\",\n",
        "    '345M',\n",
        "    None,\n",
        "    1,\n",
        "    1,\n",
        "    300,\n",
        "    1,\n",
        "    0,\n",
        "    '/content/gpt-2/models'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbZPVlpqz_Wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y12jt9SV1vFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "from flask import Flask, request\n",
        "from datetime import datetime\n",
        "from flask import Flask, request, render_template\n",
        "app = Flask(__name__,template_folder='/content/gpt-2/src')\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "@app.route('/')\n",
        "def my_form():\n",
        "    return render_template('form.html')\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def my_form_post():\n",
        "    input_text = request.form['text']\n",
        "    length = request.form['length']\n",
        "    output_text=interact_model(input_text,'345M',None,1,1,int(length),1,0,'/content/gpt-2/models')\n",
        "    return output_text\n",
        "\n",
        "\n",
        "    \n",
        " \n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}