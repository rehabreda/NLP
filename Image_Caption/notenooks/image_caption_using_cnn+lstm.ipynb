{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image caption  using cnn+lstm.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZRSiDYNQLSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## import libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os \n",
        "import pickle \n",
        "import re \n",
        "import string\n",
        "from keras.applications.vgg16 import VGG16 , preprocess_input\n",
        "from keras.preprocessing.image import load_img ,img_to_array \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import LSTM ,Input ,Embedding ,Dropout ,Dense\n",
        "from keras.layers.merge import  add\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87T5BetZQYQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### extract features from image \n",
        "## take directory of images return  dictionary with image_id>>feature\n",
        "def extract_features(directory):\n",
        "  features={}\n",
        "  model=VGG16()\n",
        "  model.layers.pop()\n",
        "  model=Model(inputs=model.inputs,outputs=model.layers[-1].output)\n",
        "  for name in os.listdir(directory):\n",
        "    file_name=os.path.join(directory,name)\n",
        "    img=load_img(file_name,target_size=(224,224))\n",
        "    img_array=img_to_array(img)\n",
        "    img_array=img_array.reshape((1,img_array.shape[0],img_array.shape[1],img_array.shape[2]))\n",
        "    processed_img=preprocess_input(img_array)\n",
        "    feature=model.predict(processed_img,verbose=0)\n",
        "    image_id=name.split('.')[0]\n",
        "    features[image_id]=feature\n",
        "  return features  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPOlux01DGZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F9FfyFSQl_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img=load_img('/content/drive/My Drive/Flicker8k_Dataset/369360998_ba56fb436f.jpg')\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xalsFDNyQp66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract features from all images\n",
        "directory = '/content/drive/My Drive/Flicker8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "# save to file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XryjXIYhQ_gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beJ_3jq4JkDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## load text file \n",
        "def load_doc(doc):\n",
        "  with open(doc,'r') as f:\n",
        "    text=f.read()\n",
        "  return text  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbg5pOhxOKbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###load dexcription \n",
        "## return image_id >> list of descriptions for this image \n",
        "def load_description(doc):\n",
        "  mapping={}\n",
        "  for line in doc.split('\\n'):\n",
        "    tokens=line.split('\\t')\n",
        "    if len(line)<2:\n",
        "      continue\n",
        "    image_id,desc=tokens[0],tokens[1]\n",
        "    image_id=image_id.split('.')[0]\n",
        "    if image_id not in mapping:\n",
        "      mapping[image_id]=list()\n",
        "    mapping[image_id].append(desc)\n",
        "  return mapping     \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIoMHelHmOiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc=load_doc('/content/drive/My Drive/Flickr8k/Flickr8k.token.txt')\n",
        "descriptions=load_description(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGQOxVrAmSXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptions['2081446176_f97dc76951']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV5OJBhemUys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### clean description \n",
        "def clean_descriptions(description):\n",
        "  re_punc=re.compile('[%s]' %re.escape(string.punctuation))\n",
        "  for img_id,desc_list in description.items():\n",
        "    for i in range(len(desc_list)):\n",
        "      tokens=desc_list[i].split()\n",
        "      tokens=[word.lower() for word in tokens]\n",
        "      tokens=[re_punc.sub('',word) for word in tokens]\n",
        "      tokens=[word for word in tokens if len(word)>1]\n",
        "      tokens=[word for word in tokens if word.isalpha()]\n",
        "      desc_list[i]=' '.join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8n--iYemXX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_descriptions(descriptions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsJExkU0mZl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### load set \n",
        "##  return identifier \n",
        "def load_set(file_name):\n",
        "  doc=load_doc(file_name)\n",
        "  identifiers=[]\n",
        "  for line in doc.split('\\n'):\n",
        "    if len(line)<1:\n",
        "      continue\n",
        "    image_id=  line.split('.')[0]\n",
        "    identifiers.append(image_id)\n",
        "  return set(identifiers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed-Gay9bmbgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_descriptions(descriptions,file_name):\n",
        "  lines=[]\n",
        "  for img_id ,desc_list in descriptions.items():\n",
        "    for desc in desc_list:\n",
        "      lines.append(img_id+' '+desc)\n",
        "    data='\\n'.join(lines)  \n",
        "    with open(file_name,'w') as f:\n",
        "      f.write(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzBzPTowmd0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_descriptions(descriptions, 'descriptions.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMKNKrGdmf5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### load clean description \n",
        "## add start and end to sequence \n",
        "def load_clean_descriptions(filename,dataset):\n",
        "  doc=doc=load_doc(filename)\n",
        "  descriptions={}\n",
        "  for line in doc.split('\\n'):\n",
        "    tokens=line.split()\n",
        "    image_id,desc=tokens[0],tokens[1:]\n",
        "    if image_id in dataset:\n",
        "      if image_id not in descriptions:\n",
        "        descriptions[image_id]=list()\n",
        "      desc='startseq '+' '.join(desc)  +' endseq'\n",
        "      descriptions[image_id].append(desc)\n",
        "  return descriptions    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez5872sOoYiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### get features of data set \n",
        "def load_photo_features(filename,dataset):\n",
        "  all_feature=pickle.load(open(filename, 'rb'))\n",
        "  feature={k:all_feature[k] for k in dataset  }\n",
        "  return feature "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su3rc-i4odwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert descriptions to lines \n",
        "def to_lines(discriptions):\n",
        "  all_desc=[]\n",
        "  for k in discriptions.keys():\n",
        "    [all_desc.append(d) for d in discriptions[k]]\n",
        "  return all_desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkxAen6BohqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### create tokenizer\n",
        "def create_tokenizer(descriptions):\n",
        "  lines=to_lines(descriptions)\n",
        "  tokenizer=Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return tokenizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-W3RT21okIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(descriptions):\n",
        "  lines=to_lines(descriptions)\n",
        "  return max([len(d.split())for d in lines])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5WBjeDhomJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### create seqiences image ,input sequence ,word\n",
        "\n",
        "\n",
        "def create_sequences(tokenizer,max_length,descriptions,image_feature):\n",
        "  vocab_size=len(tokenizer.word_index) +1\n",
        "  x1,x2,y=list(),list(),list()\n",
        "  for img_id,desc_list in descriptions.items():\n",
        "    for desc in desc_list:\n",
        "      tokens=tokenizer.texts_to_sequences([desc])[0]\n",
        "      for i in range(1,len(tokens)):\n",
        "        seq_in,seq_out=tokens[:i],tokens[i]\n",
        "        seq_in=pad_sequences([seq_in],maxlen=max_length)[0]\n",
        "        seq_out=to_categorical([seq_out],num_classes=vocab_size)[0]\n",
        "        x1.append(image_feature[img_id].reshape((4096,)))\n",
        "        x2.append(seq_in)\n",
        "        y.append(seq_out)\n",
        "\n",
        "  return  np.array(x1)  ,np.array(x2)   , np.array(y)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7BdQa8poodD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### define model \n",
        "def define_model(vocab_size, max_length):\n",
        "  ### feature extractor model\n",
        "  input_1=Input(shape=(4096,))\n",
        "  fe1=Dropout(.5)(input_1)\n",
        "  fe2=Dense(256,activation='relu')(fe1)\n",
        "\n",
        "  #### sequence model\n",
        "  input_2=Input(shape=(max_length,))\n",
        "  se1=Embedding(vocab_size,256,mask_zero=True)(input_2)\n",
        "  se2=Dropout(.5)(se1)\n",
        "  se3=LSTM(256)(se2)\n",
        "\n",
        "\n",
        "  ###decoder model\n",
        "  de1=add([fe2,se3])\n",
        "  de2=Dense(256,activation='relu')(de1)\n",
        "  outputs =Dense(vocab_size,activation='softmax')(de2)\n",
        "\n",
        "  model=Model(inputs=[input_1,input_2],outputs=outputs )\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHJd1UL8oq3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### load traing data set\n",
        "train=load_set('/content/drive/My Drive/Flickr8k/Flickr_8k.trainImages.txt')\n",
        "train=list(train)\n",
        "train_descriptions= load_clean_descriptions('/content/descriptions.txt',train[:3000])\n",
        "train_features = load_photo_features('/content/features.pkl', train[:3000])\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "# determine the maximum sequence length\n",
        "max_length =34 \n",
        "print('Description Length: %d' % max_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HShWYZ4zov2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions, train_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUym6TnU-qoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6IgZ0Z8pJf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load test set\n",
        "filename = '/content/drive/My Drive/Flickr8k/Flickr_8k.devImages.txt'\n",
        "test = load_set(filename)\n",
        "test=list(test)\n",
        "print('Dataset: %d' % len(test))\n",
        "# descriptions\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test[:1000])\n",
        "print('Descriptions: test=%d' % len(test_descriptions))\n",
        "# photo features\n",
        "test_features = load_photo_features('/content/features.pkl', test[:1000])\n",
        "print('Photos: test=%d' % len(test_features))\n",
        "# prepare sequences\n",
        "X1test, X2test, ytest = create_sequences(tokenizer, max_length, test_descriptions, test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWxJlZMAAw4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3fQpE4OpfE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = define_model(vocab_size, max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbEWeG5AuCTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqLj-TjHuGqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([X1train, X2train], ytrain, epochs=20, verbose=2, callbacks=[checkpoint], validation_data=([X1test, X2test], ytest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuqLjWmhuPMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### map int to word\n",
        "def word_for_id(integer,tokenizier):\n",
        "  for word,id in tokenizier.word_index.items():\n",
        "    if id==integer:\n",
        "      return word\n",
        "  return None    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P44ddbUEAED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### generate sequence\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "  in_text='startseq'\n",
        "  for i in range(max_length):\n",
        "    encodded=tokenizer.texts_to_sequences([in_text])[0]\n",
        "    padded_encodded=pad_sequences([encodded],maxlen=max_length)\n",
        "    prediction=model.predict([photo,padded_encodded],verbose=0)\n",
        "    prediction=np.argmax(prediction)\n",
        "    word=word_for_id(prediction,tokenizer)\n",
        "    if word is None :\n",
        "      break\n",
        "    in_text= ' '+word\n",
        "    if word== 'endseq' :\n",
        "      break\n",
        "  return  in_text  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-yf8Z_5GwUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### remove startseq and endseq from sequence\n",
        "def cleanup_summary(summary):\n",
        "  index=summary.find('startseq ')\n",
        "  if index >-1:\n",
        "    summary=summary[len('startseq '):]\n",
        "  index=summary.find(' endseq')\n",
        "  if index >-1:\n",
        "    summary=summary[:index]  \n",
        "  return  summary \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulLyeFpMLOOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# clean up prediction\n",
        "\t\tyhat = cleanup_summary(yhat)\n",
        "\t\t# store actual and predicted\n",
        "\t\treferences = [cleanup_summary(d).split() for d in desc_list]\n",
        "\t\tactual.append(references)\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBenjpUJLxEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC1qn3kwL-9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMt60km1NgWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract features from each photo in the directory\n",
        "def extract_features(filename):\n",
        "\t# load the model\n",
        "\tmodel = VGG16()\n",
        "\t# re-structure the model\n",
        "\tmodel.layers.pop()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\t# load the photo\n",
        "\timage = load_img(filename, target_size=(224, 224))\n",
        "\t# convert the image pixels to a numpy array\n",
        "\timage = img_to_array(image)\n",
        "\t# reshape data for the model\n",
        "\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t# prepare the image for the VGG model\n",
        "\timage = preprocess_input(image)\n",
        "\t# get features\n",
        "\tfeature = model.predict(image, verbose=0)\n",
        "\treturn feature\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaSSOv8DNw3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a description for an image\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\t# seed the generation process\n",
        "\tin_text = 'startseq'\n",
        "\t# iterate over the whole length of the sequence\n",
        "\tfor _ in range(max_length):\n",
        "\t\t# integer encode input sequence\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pad input\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\t# predict next word\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\t# convert probability to integer\n",
        "\t\tyhat = np.argmax(yhat)\n",
        "\t\t# map integer to word\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\t# stop if we cannot map the word\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\t# append as input for generating the next word\n",
        "\t\tin_text += ' ' + word\n",
        "\t\t# stop if we predict the end of the sequence\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVHtW4voNxiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "photo = extract_features('/content/sample_data/example.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvlSevDLOOqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "photo.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx2a5plsOQrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "description = generate_desc(model, tokenizer, photo, max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MqWF-zbOTXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "description"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIdmV_dkOaIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "description = cleanup_summary(description)\n",
        "print(description)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xmxPw3ZOduK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}