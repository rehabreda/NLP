{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rehabreda/NLP/blob/master/translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "51PWakVPixKx",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "c2742a3d-ef1a-4589-9f47-746e0924ab4a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f5a874b2-176a-448c-9663-b587dc27119e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f5a874b2-176a-448c-9663-b587dc27119e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving spa.txt to spa.txt\n",
            "User uploaded file \"spa.txt\" with length 8152302 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "81llPJymjGym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "554205b7-93dc-4be2-b596-2a5008f9a4e3"
      },
      "cell_type": "code",
      "source": [
        "###import libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense ,LSTM ,Input ,Embedding \n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "TlTgjqi1mdMO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as k\n",
        "if len(k.tensorflow_backend._get_available_gpus())>0:\n",
        "  from keras.layers import CuDNNLSTM as LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fuoV5Nq-nTZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## congiguration\n",
        "batch_size=64\n",
        "epochs=100\n",
        "latent_dim=265\n",
        "max_samples=10000\n",
        "max_sequence_length=100\n",
        "max_num_words=20000\n",
        "embedding_dim=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u3Apr89OohdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_texts=[]\n",
        "target_texts=[]\n",
        "target_texts_input=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZe8ji5to515",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t=0\n",
        "for line in open('spa.txt'):\n",
        "  t+=1\n",
        "  if t> max_samples:\n",
        "    break\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "  input_text,translation=line.rstrip().split('\\t')\n",
        "  target_text=translation +' <eos>'\n",
        "  target_text_input='<sos> ' +translation\n",
        "  \n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  target_texts_input.append(target_text_input)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C7Fl4ZP6qfon",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###tokinizer input\n",
        "tokenizer_inputs=Tokenizer(num_words=max_num_words)\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences=tokenizer_inputs.texts_to_sequences(input_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJYpukIFrSOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2idx_inputs=tokenizer_inputs.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eWlaEJ_grYkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len_input=max(len(s) for s in input_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_TLNKCnrkHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##tokenizer targers\n",
        "tokenizer_targets=Tokenizer(num_words=max_num_words,filters='')\n",
        "tokenizer_targets.fit_on_texts(target_texts+target_texts_input)\n",
        "target_sequences=tokenizer_targets.texts_to_sequences(target_texts)\n",
        "target_sequences_input=tokenizer_targets.texts_to_sequences(target_texts_input)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X87yaMpluhdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2idx_targets=tokenizer_targets.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YU_N3V8xutdB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len_target=max(len(s) for s in target_sequences )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddZKgso4u2_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_words_target=len(word2idx_targets)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KZBuptT9vBVZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###pad sequences\n",
        "encoder_inputs=pad_sequences(input_sequences,maxlen=max_len_input)\n",
        "\n",
        "decoder_inputs=pad_sequences(target_sequences_input,maxlen=max_len_target,padding='post')\n",
        "\n",
        "decoder_outputs=pad_sequences(target_sequences,maxlen=max_len_target,padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ckDMYBctvrSj",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 41
        },
        "outputId": "d0553501-4e7a-451e-9aac-87b56ee68902"
      },
      "cell_type": "code",
      "source": [
        "## load pre-trained nodel\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f13181ca-7071-41c2-9acf-8986348b3077\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f13181ca-7071-41c2-9acf-8986348b3077\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XQJH_HaWyybB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec4739bd-f5e6-47d0-f98c-33b287ee9a55"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  \u001b[0m\u001b[01;34msample_data\u001b[0m/  spa.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MaKYkA_Jv5O9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9d7a5e7f-3413-4e67-d218-d7daab88fcc6"
      },
      "cell_type": "code",
      "source": [
        "word2vec={}\n",
        "\n",
        "for line in open('glove.6B.100d.txt'):\n",
        "  values=line.split()\n",
        "  word=values[0]\n",
        "  vec=np.asarray(values[1:],dtype='float32')\n",
        "  word2vec[word]=vec\n",
        "  \n",
        "print('Found %s word vectors.' % len(word2vec))\n",
        "  \n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 340790 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eaYYKa1FxB_x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## embedding matrix\n",
        "num_words=min(max_num_words,len(word2idx_inputs)+1)\n",
        "embedding_matrix=np.zeros((num_words,embedding_dim))\n",
        "\n",
        "for word,idx in word2idx_inputs.items():\n",
        "  if idx< max_num_words:\n",
        "    embedding_vector=word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[idx]=embedding_vector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCbGCAAxyQHA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## create embedding layer\n",
        "embedding_layer=Embedding(num_words,embedding_dim,weights=[embedding_matrix],input_length=max_len_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWQXyT6gyp25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_targets_one_hot=np.zeros((len(input_texts),max_len_target,num_words_target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-HEeZuKzTx2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i ,s in enumerate(decoder_outputs):\n",
        "  for t,word in enumerate(s):\n",
        "    decoder_targets_one_hot[i,t,word]=1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpfHonY_LHXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "d88ceda9-a7ce-4e09-a9eb-079d6557a6e8"
      },
      "cell_type": "code",
      "source": [
        "## build model \n",
        "encoder_input_placeholder=Input(shape=(max_len_input,))\n",
        "x=embedding_layer(encoder_input_placeholder)\n",
        "encoder=LSTM(latent_dim,return_state=True)\n",
        "encoder_output,h,c=encoder(x)\n",
        "encoder_states=[h,c]\n",
        "\n",
        "##decoder\n",
        "decoder_input_placeholder=Input(shape=(max_len_target,))\n",
        "decoder_embedding=Embedding(num_words_target,latent_dim)\n",
        "decoder_output_x=decoder_embedding(decoder_input_placeholder)\n",
        "decoder=LSTM(latent_dim,return_state=True,return_sequences=True)\n",
        "decoder_output,_,_=decoder(decoder_output_x,initial_state=encoder_states)\n",
        "\n",
        "decoder_dense=Dense(num_words_target,activation='softmax')\n",
        "decoder_output=decoder_dense(decoder_output)\n",
        "model=Model([encoder_input_placeholder,decoder_input_placeholder],decoder_output)                    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "egQlGHtdNrIj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "loss='categorical_crossentropy',\n",
        "optimizer='rmsprop',\n",
        "metrics=['accuracy']       \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDjrgDgfOLHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3934
        },
        "outputId": "296110c1-9d10-4fc9-8f09-1b441f241dbc"
      },
      "cell_type": "code",
      "source": [
        "model.fit([encoder_inputs,decoder_inputs],decoder_targets_one_hot,batch_size=batch_size,epochs=epochs,validation_split=.2)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 2.6202 - acc: 0.6605 - val_loss: 2.5767 - val_acc: 0.6606\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 2.0101 - acc: 0.7152 - val_loss: 2.4134 - val_acc: 0.6746\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.8047 - acc: 0.7364 - val_loss: 2.2502 - val_acc: 0.6893\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.6440 - acc: 0.7549 - val_loss: 2.1652 - val_acc: 0.7068\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.5151 - acc: 0.7711 - val_loss: 2.0454 - val_acc: 0.7215\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.4038 - acc: 0.7832 - val_loss: 2.0169 - val_acc: 0.7273\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.3049 - acc: 0.7951 - val_loss: 1.9902 - val_acc: 0.7306\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.2190 - acc: 0.8039 - val_loss: 1.9570 - val_acc: 0.7337\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.1449 - acc: 0.8127 - val_loss: 1.9589 - val_acc: 0.7341\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.0757 - acc: 0.8205 - val_loss: 1.9345 - val_acc: 0.7362\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 1.0151 - acc: 0.8284 - val_loss: 1.9388 - val_acc: 0.7327\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.9622 - acc: 0.8365 - val_loss: 1.9822 - val_acc: 0.7328\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.9140 - acc: 0.8445 - val_loss: 1.9740 - val_acc: 0.7300\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.8678 - acc: 0.8497 - val_loss: 1.9791 - val_acc: 0.7311\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.8216 - acc: 0.8576 - val_loss: 1.9640 - val_acc: 0.7333\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.7804 - acc: 0.8630 - val_loss: 1.9647 - val_acc: 0.7347\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.7392 - acc: 0.8693 - val_loss: 1.9828 - val_acc: 0.7307\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.7028 - acc: 0.8751 - val_loss: 1.9923 - val_acc: 0.7336\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.6726 - acc: 0.8793 - val_loss: 1.9969 - val_acc: 0.7351\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.6426 - acc: 0.8853 - val_loss: 2.0194 - val_acc: 0.7341\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.6149 - acc: 0.8889 - val_loss: 2.0383 - val_acc: 0.7323\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.5858 - acc: 0.8935 - val_loss: 2.0461 - val_acc: 0.7321\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.5608 - acc: 0.8970 - val_loss: 2.0676 - val_acc: 0.7334\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.5336 - acc: 0.9010 - val_loss: 2.0861 - val_acc: 0.7323\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.5099 - acc: 0.9055 - val_loss: 2.0823 - val_acc: 0.7313\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4848 - acc: 0.9076 - val_loss: 2.0919 - val_acc: 0.7316\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4628 - acc: 0.9117 - val_loss: 2.1352 - val_acc: 0.7299\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4441 - acc: 0.9147 - val_loss: 2.1248 - val_acc: 0.7297\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4274 - acc: 0.9173 - val_loss: 2.1548 - val_acc: 0.7298\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4139 - acc: 0.9197 - val_loss: 2.1972 - val_acc: 0.7305\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3989 - acc: 0.9218 - val_loss: 2.1672 - val_acc: 0.7301\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3862 - acc: 0.9243 - val_loss: 2.1992 - val_acc: 0.7284\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3728 - acc: 0.9260 - val_loss: 2.2093 - val_acc: 0.7289\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3598 - acc: 0.9289 - val_loss: 2.2264 - val_acc: 0.7297\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3486 - acc: 0.9310 - val_loss: 2.2543 - val_acc: 0.7262\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3383 - acc: 0.9327 - val_loss: 2.2411 - val_acc: 0.7272\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3275 - acc: 0.9349 - val_loss: 2.2525 - val_acc: 0.7281\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3172 - acc: 0.9368 - val_loss: 2.2782 - val_acc: 0.7256\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3081 - acc: 0.9385 - val_loss: 2.2759 - val_acc: 0.7263\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3004 - acc: 0.9397 - val_loss: 2.2976 - val_acc: 0.7278\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2930 - acc: 0.9409 - val_loss: 2.2900 - val_acc: 0.7272\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2865 - acc: 0.9421 - val_loss: 2.3190 - val_acc: 0.7262\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2817 - acc: 0.9432 - val_loss: 2.3096 - val_acc: 0.7271\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2754 - acc: 0.9447 - val_loss: 2.3220 - val_acc: 0.7265\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2707 - acc: 0.9446 - val_loss: 2.3265 - val_acc: 0.7257\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2656 - acc: 0.9456 - val_loss: 2.3303 - val_acc: 0.7263\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2596 - acc: 0.9474 - val_loss: 2.3336 - val_acc: 0.7265\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2544 - acc: 0.9475 - val_loss: 2.3479 - val_acc: 0.7238\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2491 - acc: 0.9485 - val_loss: 2.3507 - val_acc: 0.7247\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2453 - acc: 0.9490 - val_loss: 2.3499 - val_acc: 0.7242\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2398 - acc: 0.9500 - val_loss: 2.3595 - val_acc: 0.7242\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2354 - acc: 0.9502 - val_loss: 2.3611 - val_acc: 0.7226\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2318 - acc: 0.9509 - val_loss: 2.3761 - val_acc: 0.7244\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2286 - acc: 0.9515 - val_loss: 2.3784 - val_acc: 0.7233\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2256 - acc: 0.9522 - val_loss: 2.3809 - val_acc: 0.7232\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2228 - acc: 0.9519 - val_loss: 2.3774 - val_acc: 0.7243\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2206 - acc: 0.9528 - val_loss: 2.3811 - val_acc: 0.7228\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2175 - acc: 0.9526 - val_loss: 2.3891 - val_acc: 0.7236\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 8s 999us/step - loss: 0.2147 - acc: 0.9533 - val_loss: 2.4052 - val_acc: 0.7240\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2114 - acc: 0.9535 - val_loss: 2.3929 - val_acc: 0.7235\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2079 - acc: 0.9534 - val_loss: 2.4196 - val_acc: 0.7217\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2055 - acc: 0.9540 - val_loss: 2.4226 - val_acc: 0.7239\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2024 - acc: 0.9542 - val_loss: 2.4133 - val_acc: 0.7224\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.2004 - acc: 0.9546 - val_loss: 2.4171 - val_acc: 0.7224\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1992 - acc: 0.9547 - val_loss: 2.4253 - val_acc: 0.7234\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1973 - acc: 0.9549 - val_loss: 2.4387 - val_acc: 0.7213\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1955 - acc: 0.9552 - val_loss: 2.4306 - val_acc: 0.7217\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1930 - acc: 0.9554 - val_loss: 2.4394 - val_acc: 0.7212\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1915 - acc: 0.9547 - val_loss: 2.4425 - val_acc: 0.7237\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1892 - acc: 0.9562 - val_loss: 2.4520 - val_acc: 0.7215\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1874 - acc: 0.9558 - val_loss: 2.4533 - val_acc: 0.7206\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1866 - acc: 0.9559 - val_loss: 2.4730 - val_acc: 0.7209\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1849 - acc: 0.9563 - val_loss: 2.4709 - val_acc: 0.7201\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1829 - acc: 0.9568 - val_loss: 2.4768 - val_acc: 0.7194\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1821 - acc: 0.9566 - val_loss: 2.4811 - val_acc: 0.7198\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1814 - acc: 0.9562 - val_loss: 2.4849 - val_acc: 0.7207\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1797 - acc: 0.9561 - val_loss: 2.4839 - val_acc: 0.7210\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1781 - acc: 0.9564 - val_loss: 2.5013 - val_acc: 0.7185\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1768 - acc: 0.9569 - val_loss: 2.4908 - val_acc: 0.7187\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1759 - acc: 0.9565 - val_loss: 2.4951 - val_acc: 0.7201\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1747 - acc: 0.9566 - val_loss: 2.5056 - val_acc: 0.7201\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1734 - acc: 0.9570 - val_loss: 2.5139 - val_acc: 0.7191\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1721 - acc: 0.9566 - val_loss: 2.5105 - val_acc: 0.7197\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1706 - acc: 0.9569 - val_loss: 2.5213 - val_acc: 0.7214\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1693 - acc: 0.9571 - val_loss: 2.5122 - val_acc: 0.7186\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1677 - acc: 0.9569 - val_loss: 2.5135 - val_acc: 0.7197\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1665 - acc: 0.9569 - val_loss: 2.5247 - val_acc: 0.7185\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1649 - acc: 0.9567 - val_loss: 2.5207 - val_acc: 0.7192\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1644 - acc: 0.9573 - val_loss: 2.5108 - val_acc: 0.7203\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1634 - acc: 0.9569 - val_loss: 2.5270 - val_acc: 0.7178\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1628 - acc: 0.9567 - val_loss: 2.5258 - val_acc: 0.7182\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1614 - acc: 0.9568 - val_loss: 2.5236 - val_acc: 0.7198\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1610 - acc: 0.9577 - val_loss: 2.5340 - val_acc: 0.7191\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1595 - acc: 0.9574 - val_loss: 2.5214 - val_acc: 0.7191\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1594 - acc: 0.9567 - val_loss: 2.5460 - val_acc: 0.7174\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1591 - acc: 0.9568 - val_loss: 2.5344 - val_acc: 0.7176\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1579 - acc: 0.9569 - val_loss: 2.5303 - val_acc: 0.7183\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1576 - acc: 0.9571 - val_loss: 2.5380 - val_acc: 0.7191\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1569 - acc: 0.9572 - val_loss: 2.5421 - val_acc: 0.7199\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 0.1566 - acc: 0.9571 - val_loss: 2.5439 - val_acc: 0.7173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f136368e7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "pm4dBEX4OoiP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## make prediction  \n",
        "## build sampling model \n",
        "\n",
        "## encoder\n",
        "encoder_model = Model(encoder_input_placeholder, encoder_states)\n",
        "\n",
        "decoder_input_h=Input(shape=(latent_dim,))\n",
        "decoder_input_c=Input(shape=(latent_dim,))\n",
        "decoder_states_input=[decoder_input_h,decoder_input_c]\n",
        "\n",
        "decoder_input_signle=Input(shape=(1,))\n",
        "decoder_input_signle_x=decoder_embedding(decoder_input_signle)\n",
        "decoder_output,h,c=decoder(decoder_input_signle_x,initial_state=decoder_states_input)\n",
        "decoder_states=[h,c]\n",
        "\n",
        "decoder_output=decoder_dense(decoder_output)\n",
        "\n",
        "decoder_model=Model([decoder_input_signle]+decoder_states_input,[decoder_output]+ decoder_states)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehUROOEgOXAe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx2word_inputs={v:k for k,v in word2idx_inputs.items()}\n",
        "idx2word_targets={v:k for k,v in word2idx_targets.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2RMYsdmRuZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "  states=encoder_model.predict(input_seq)\n",
        "  target_seq=np.zeros((1,1))\n",
        "  \n",
        "  target_seq[0,0]=word2idx_targets['<sos>']\n",
        "  \n",
        "  eos=word2idx_targets['<eos>']\n",
        "  output_sentence=[]\n",
        "  \n",
        "  for i in range(max_len_target):\n",
        "    output,h,c=decoder_model.predict(\n",
        "      [target_seq] + states\n",
        ")\n",
        "    \n",
        "    idx=np.argmax(output[0,0,:])\n",
        "    if idx==eos:\n",
        "      break\n",
        "      \n",
        "    word=''\n",
        "    if idx>0:\n",
        "      word=idx2word_targets[idx]\n",
        "      output_sentence.append(word)\n",
        "    target_seq[0,0]=idx\n",
        "    states=[h,c]\n",
        "    \n",
        "    \n",
        "  return ' '.join(output_sentence)  \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "    \n",
        "    \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d-8bsu4TUxWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "4d6d65d1-0062-4832-db59-d56e640c99f2"
      },
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  i=np.random.choice(len(input_texts))\n",
        "  input_seq=encoder_inputs[i:i+1]\n",
        "  translation=decode_sequence(input_seq)\n",
        "  print('Input:', input_texts[i])\n",
        "  print('Translation:', translation)\n",
        "  \n",
        "  ans = input(\"Continue? [Y/n]\")\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "     break\n",
        "  "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: They know Tom.\n",
            "Translation: conocen a tom.\n",
            "Continue? [Y/n]y\n",
            "Input: Nobody laughed.\n",
            "Translation: nadie se rió.\n",
            "Continue? [Y/n]n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RY6kHpN890PP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}